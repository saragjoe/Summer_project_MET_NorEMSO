{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0015154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import xarray as xr\n",
    "import numpy as np \n",
    "import xroms\n",
    "import xarray as xr\n",
    "import pyresample \n",
    "import metpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd053509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def txt_to_pd(txtfile,LAT,LON):\n",
    "\n",
    "    columns_to_keep = ['T_degC', 'T_qf', 'S', 'S_qf', 'Date', 'Time'] \n",
    "    new_column_names = ['TEMP','TEMP_QC','PSAL','PSAL_QC','Date','Time']\n",
    "\n",
    "\n",
    "    # Hvis vi vil at pandas skal tolke dato som som et datetime object \n",
    "    # kan vi gi informasjon om hvordan dato stirngene er formatert med parser.  \n",
    "    #\n",
    "    # For denne filen vil det kunne se slik ut:\n",
    "    # parse = lambda x: datetime.datetime.strptime(x, '%d %b %Y %H:%M:%S')\n",
    "    # Betydningen av de ulike %bokstaven finnes her: (https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)\n",
    "\n",
    "    # Men for å gjøre ting litt vanskligere er det brukt norske forkortelser for månedsnavn... \n",
    "    # Vi bytter enkelt ut norske forkortelser med engelske ved å bruke metoden .replace(norsk, engelsk)\n",
    "\n",
    "    parse = lambda x: datetime.datetime.strptime(x.replace('Des', 'Dec').replace('Mai', 'May').replace('Okt', 'Oct'), '%d %b %Y %H:%M:%S')\n",
    "\n",
    "    #df = pd.read_csv(txtfile, delimiter='\\t', usecols=columns_to_keep, parse_dates={\"Datetime\" : ['Date', 'Time']}, date_parser = parse)\n",
    "    df = pd.read_csv(txtfile, delimiter='\\t', usecols=columns_to_keep)\n",
    "    df.columns = new_column_names\n",
    "    \n",
    "    # Combine Date and Time columns and strip any leading or trailing whitespace\n",
    "    df['TIME'] = (df['Date'] + ' ' + df['Time']).str.strip()\n",
    "    \n",
    "    # Apply the custom parsing function\n",
    "    df['TIME'] = df['TIME'].apply(parse)\n",
    "    df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "    \n",
    "    # Add depth:\n",
    "    df['DEPTH'] = get_depth(txtfile)\n",
    "    df['LAT'] = LAT\n",
    "    df['LON'] = LON\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def netcdf_to_pd(txt):\n",
    "    # Load the NetCDF file using xarray\n",
    "    ds = xr.open_dataset(txt)\n",
    "\n",
    "    # Select the variables you are interested in\n",
    "    variables = ['TEMP', 'TEMP_QC', 'PSAL', 'PSAL_QC']\n",
    "\n",
    "    # Initialize an empty DataFrame to merge into\n",
    "    df_combined = pd.DataFrame()\n",
    "\n",
    "    # Loop over each variable to process and merge\n",
    "    for var in variables:\n",
    "\n",
    "        # Select the variable data\n",
    "        data = ds[var]\n",
    "    \n",
    "        # Stack the depth and time dimensions into a MultiIndex\n",
    "        stacked_data = data.stack(points=('DEPTH', 'TIME'))\n",
    "    \n",
    "    \n",
    "        # Convert the stacked DataArray to a pandas DataFrame\n",
    "        df = stacked_data.to_dataframe()\n",
    "            \n",
    "        # Temporarily rename columns to avoid conflicts\n",
    "        df.rename(columns={'DEPTH': 'Depth_col', 'TIME': 'Time_col', 'LONGITUDE': 'LON_col'}, inplace=True)\n",
    "        #        \n",
    "        df = df.reset_index()\n",
    "        df.drop(columns=['Depth_col', 'Time_col'], inplace=True)\n",
    "        #    \n",
    "        # If df_combined is empty, initialize it with the current DataFrame\n",
    "        if df_combined.empty:\n",
    "            df_combined = df\n",
    "        else:\n",
    "            # Merge the current DataFrame with the combined DataFrame\n",
    "            df_combined = pd.merge(df_combined, df, on=['DEPTH', 'TIME'], how='outer')  \n",
    "    df_combined['LON'] = ds['LONGITUDE'].values[0]\n",
    "    df_combined['LAT'] = ds['LATITUDE'].values[0]\n",
    "    return(df_combined)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9f5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c90c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a45c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc8a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth(filename):\n",
    "    # Use a regular expression to extract the depth value\n",
    "    depth_match = re.search(r'_(\\d+)m', filename)\n",
    "    if depth_match:\n",
    "        depth_value = int(depth_match.group(1))\n",
    "    else:\n",
    "        depth_value = None\n",
    "    return(depth_value)   \n",
    "\n",
    "def get_Zindices(ds,X,Y,target_depth):\n",
    "    ds = ds.isel(xi_rho = X, eta_rho = Y)\n",
    "\n",
    "    # Extract the z_rho values at the given point\n",
    "    z_rho_values = ds.z_rho.values\n",
    "    s_rho_values = ds.s_rho.values\n",
    "\n",
    "    diff = np.abs(z_rho_values - target_depth)\n",
    "    \n",
    "    # Find the indices of the two smallest differences\n",
    "    closest_indices = diff.argsort()[0][:2]\n",
    "    \n",
    "    return(closest_indices)\n",
    "\n",
    "def find_time_index(r_time,ocean_time):\n",
    "    days_since_1970 = (r_time - datetime.datetime(1970,1,1,0,0,0)).total_seconds()\n",
    "    ocean_time = pd.to_datetime(ocean_time)\n",
    "    # Convert ocean_time\n",
    "    ocean_time_since_1970 = (ocean_time - datetime.datetime(1970,1,1,0,0,0)).total_seconds()\n",
    "    index = np.abs(ocean_time_since_1970 - days_since_1970).argmin()\n",
    "    return(index)\n",
    "\n",
    "def get_XYpositions(filename, lons, lats):\n",
    "    \n",
    "    fh = xr.open_dataset(filename)\n",
    "    x   = np.linspace(0, fh.lat_rho.values.shape[1]-1, fh.lat_rho.values.shape[1])\n",
    "    y   = np.linspace(0, fh.lat_rho.values.shape[0]-1, fh.lat_rho.values.shape[0])\n",
    "    xi  = np.zeros_like(fh.lon_rho.values)\n",
    "    yi  = np.zeros([fh.lon_rho.values.shape[1], fh.lon_rho.values.shape[0]])\n",
    "    xi[:,:] = x\n",
    "    yi[:,:] = y\n",
    "    yi  = np.swapaxes(yi, 1, 0)\n",
    "\n",
    "    # First I define the wet points of the field as the lon,lat values with mask_rho==1 \n",
    "    sea_def = pyresample.geometry.SwathDefinition(lons= fh.lon_rho.values[np.where(fh.mask_rho)], lats = fh.lat_rho.values[np.where(fh.mask_rho)])\n",
    "\n",
    "    # Second, the full grid definiton (our target domain):\n",
    "    orig_def = pyresample.geometry.SwathDefinition(lons=lons, lats=lats)\n",
    "\n",
    "    # Then I fill the temperature field by the nearest neighbour approace.\n",
    "    # Note that only wet points are used as input. \n",
    "\n",
    "    # The radius of influence sets a limit (in meters) for how far away a true value can be from the point that will be filled\n",
    "\n",
    "    ypos = pyresample.kd_tree.resample_nearest(sea_def, yi[np.where(fh.mask_rho)], \\\n",
    "                               orig_def, radius_of_influence=2400)\n",
    "\n",
    "    xpos = pyresample.kd_tree.resample_nearest(sea_def, xi[np.where(fh.mask_rho)], \\\n",
    "                               orig_def, radius_of_influence=2400)\n",
    "    return np.array([int(x) for x in xpos]), np.array([int(y) for y in ypos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f74483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TEMP  TEMP_QC       PSAL  PSAL_QC                TIME  DEPTH     LAT  \\\n",
      "0 -0.4358        1  34.911854        1 2021-11-27 12:00:00   1000  66.015   \n",
      "1 -0.4623        1  34.912240        1 2021-11-27 13:00:00   1000  66.015   \n",
      "2 -0.4573        1  34.910988        1 2021-11-27 14:00:00   1000  66.015   \n",
      "3 -0.4505        1  34.910341        1 2021-11-27 15:00:00   1000  66.015   \n",
      "4 -0.4569        1  34.910742        1 2021-11-27 16:00:00   1000  66.015   \n",
      "5 -0.4477        1  34.910972        1 2021-11-27 17:00:00   1000  66.015   \n",
      "6 -0.4445        1  34.912828        1 2021-11-27 18:00:00   1000  66.015   \n",
      "7 -0.4573        1  34.910747        1 2021-11-27 19:00:00   1000  66.015   \n",
      "8 -0.4678        1  34.910478        1 2021-11-27 20:00:00   1000  66.015   \n",
      "9 -0.4424        1  34.909580        1 2021-11-27 21:00:00   1000  66.015   \n",
      "\n",
      "     LON    X    Y         DAY  \n",
      "0  1.983  406  340  2021-11-27  \n",
      "1  1.983  406  340  2021-11-27  \n",
      "2  1.983  406  340  2021-11-27  \n",
      "3  1.983  406  340  2021-11-27  \n",
      "4  1.983  406  340  2021-11-27  \n",
      "5  1.983  406  340  2021-11-27  \n",
      "6  1.983  406  340  2021-11-27  \n",
      "7  1.983  406  340  2021-11-27  \n",
      "8  1.983  406  340  2021-11-27  \n",
      "9  1.983  406  340  2021-11-27  \n",
      "   DEPTH                TIME    TEMP  TEMP_QC       PSAL  PSAL_QC    LON  \\\n",
      "0  500.0 2020-08-25 12:00:00  3.4393      1.0  34.927509      1.0  2.203   \n",
      "1  500.0 2020-08-25 13:00:00  3.2461      1.0  34.923210      1.0  2.203   \n",
      "2  500.0 2020-08-25 14:00:00  3.3105      1.0  34.926910      1.0  2.203   \n",
      "3  500.0 2020-08-25 15:00:00  3.1996      1.0  34.920109      1.0  2.203   \n",
      "4  500.0 2020-08-25 16:00:00  3.3045      1.0  34.922409      1.0  2.203   \n",
      "5  500.0 2020-08-25 17:00:00  3.3850      1.0  34.919609      1.0  2.203   \n",
      "6  500.0 2020-08-25 18:00:00  3.3211      1.0  34.924210      1.0  2.203   \n",
      "7  500.0 2020-08-25 19:00:00  3.3075      1.0  34.923012      1.0  2.203   \n",
      "8  500.0 2020-08-25 20:00:00  3.2128      1.0  34.917912      1.0  2.203   \n",
      "9  500.0 2020-08-25 21:00:00  3.4751      1.0  34.928108      1.0  2.203   \n",
      "\n",
      "         LAT    X    Y         DAY  \n",
      "0  65.829002  400  333  2020-08-25  \n",
      "1  65.829002  400  333  2020-08-25  \n",
      "2  65.829002  400  333  2020-08-25  \n",
      "3  65.829002  400  333  2020-08-25  \n",
      "4  65.829002  400  333  2020-08-25  \n",
      "5  65.829002  400  333  2020-08-25  \n",
      "6  65.829002  400  333  2020-08-25  \n",
      "7  65.829002  400  333  2020-08-25  \n",
      "8  65.829002  400  333  2020-08-25  \n",
      "9  65.829002  400  333  2020-08-25  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "txtfile = '/lustre/storeB/project/fou/hi/projects/NorEmso/Observations/moorings/StationM/Deployment2/StaM_SBE_20211127_1000m.txt'\n",
    "ds = txt_to_pd(txtfile,66.015,1.983)\n",
    "\n",
    "deployment1 = '/lustre/storeB/project/fou/hi/projects/NorEmso/Observations/moorings/StationM/Deployment1/StationM_2021_hydrography.nc'\n",
    "ds2 = netcdf_to_pd(deployment1)\n",
    "\n",
    "gridfile = '/lustre/storeB/project/fou/hi/oper/norshelf/static_inputfiles/norshelf_2.4_vert_grd.nc'\n",
    "x,y = get_XYpositions(gridfile, ds2.LON.values, ds2.LAT.values)\n",
    "ds2['X'] = x\n",
    "ds2['Y'] = y\n",
    "\n",
    "x,y = get_XYpositions(gridfile, ds.LON.values, ds.LAT.values)\n",
    "ds['X'] = x\n",
    "ds['Y'] = y\n",
    "\n",
    "\n",
    "ds2['TIME'] = pd.to_datetime(ds2['TIME'])\n",
    "# Round the TIME column to the nearest hour\n",
    "ds2['TIME'] = ds2['TIME'].dt.round('H')\n",
    "\n",
    "ds2['DAY'] = ds2['TIME'].dt.date\n",
    "\n",
    "ds['TIME'] = pd.to_datetime(ds['TIME'])\n",
    "# Round the TIME column to the nearest hour\n",
    "ds['TIME'] = ds['TIME'].dt.round('H')\n",
    "\n",
    "ds['DAY'] = ds['TIME'].dt.date\n",
    "\n",
    "# Test-data\n",
    "ds2=ds2.head(50)\n",
    "# Test-data\n",
    "ds=ds.head(50)\n",
    "print(ds.head(10))\n",
    "print(ds2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84aa845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to extract data for each group\n",
    "def extract_data_for_group(group,dsG,var='temp'):\n",
    "    date = group['DAY'].iloc[0]  # All rows in the group have the same date\n",
    "    year = date.strftime('%Y')\n",
    "    month = date.strftime('%m')\n",
    "    day = date.strftime('%d')\n",
    "    \n",
    "    file_path = f'https://thredds.met.no/thredds/dodsC/sea_norshelf_files/{year}/{month}/norshelf_qck_an_{year}{month}{day}T00Z.nc'\n",
    "    # Read the file and extract data (assuming file has some structured data)\n",
    "    \n",
    "    try:\n",
    "        with xr.open_dataset(file_path) as ds:\n",
    "            # Selcect variables: \n",
    "            ds = ds.get([var])\n",
    "            # Here we simulate extracting relevant data from the file for each x, y\n",
    "            extracted_data = []\n",
    "            for _, row in group.iterrows():\n",
    "                x, y = row['X'], row['Y']\n",
    "                \n",
    "                #fine time-index\n",
    "                r_time = row['TIME']\n",
    "                ocean_time = ds.ocean_time.values\n",
    "                index = find_time_index(r_time,ocean_time)\n",
    "                \n",
    "                #find depth index to interpolate over:\n",
    "                depth = row['DEPTH']\n",
    "                indices = get_Zindices(dsG,x,y,depth*-1)\n",
    "                \n",
    "                # Data extraction based on x, y, time and s_rho\n",
    "                # OBS: This is just and example of extraction, have to find the correct ocean_time and s_rho!!!!\n",
    "                temp1 = ds.isel(ocean_time=index,s_rho = indices[0], xi_rho = x, eta_rho = y)[var].values\n",
    "                temp2 = ds.isel(ocean_time=index,s_rho = indices[1], xi_rho = x, eta_rho = y)[var].values\n",
    "                m=np.array([temp1,temp2])\n",
    "                extracted_data.append(np.mean(m))\n",
    "            return extracted_data\n",
    "    except:\n",
    "        for _, row in group.iterrows():\n",
    "            extracted_data.append(np.nan)\n",
    "        return extracted_data   \n",
    "        \n",
    "\n",
    "        \n",
    "gridfile = '/lustre/storeB/project/fou/hi/oper/norshelf/static_inputfiles/norshelf_2.4_vert_grd.nc'\n",
    "# Load your ROMS dataset\n",
    "dsG = xr.open_dataset(gridfile)\n",
    "# Initialize the ROMS dataset and create the grid object\n",
    "dsG, xgrid = xroms.roms_dataset(dsG, include_cell_volume=True, include_Z0=True)\n",
    "# Associate the dataset with the grid\n",
    "dsG.xroms.set_grid(xgrid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dc9e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the TIME column and apply the function to each group\n",
    "grouped = ds2.groupby('DAY').apply(lambda group: extract_data_for_group(group,dsG,'temp'))\n",
    "\n",
    "    # Flatten the grouped data into the original DataFrame\n",
    "ds2['TEMP_MOD'] = [item for sublist in grouped for item in sublist]\n",
    "\n",
    "# Group by the TIME column and apply the function to each group\n",
    "grouped = ds2.groupby('DAY').apply(lambda group: extract_data_for_group(group,dsG,'salt'))\n",
    "\n",
    "    # Flatten the grouped data into the original DataFrame\n",
    "ds2['SALT_MOD'] = [item for sublist in grouped for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dcd3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the TIME column and apply the function to each group\n",
    "grouped = ds.groupby('DAY').apply(lambda group: extract_data_for_group(group,dsG,'temp'))\n",
    "\n",
    "    # Flatten the grouped data into the original DataFrame\n",
    "ds['TEMP_MOD'] = [item for sublist in grouped for item in sublist]\n",
    "\n",
    "# Group by the TIME column and apply the function to each group\n",
    "grouped = ds.groupby('DAY').apply(lambda group: extract_data_for_group(group,dsG,'salt'))\n",
    "\n",
    "    # Flatten the grouped data into the original DataFrame\n",
    "ds['SALT_MOD'] = [item for sublist in grouped for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc77707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_QC</th>\n",
       "      <th>PSAL</th>\n",
       "      <th>PSAL_QC</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DAY</th>\n",
       "      <th>temp</th>\n",
       "      <th>salt</th>\n",
       "      <th>TEMP_MOD</th>\n",
       "      <th>SALT_MOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 12:00:00</td>\n",
       "      <td>3.4393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.927509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6405</td>\n",
       "      <td>34.952003</td>\n",
       "      <td>3.6405</td>\n",
       "      <td>34.952003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 13:00:00</td>\n",
       "      <td>3.2461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.923210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6630</td>\n",
       "      <td>34.953003</td>\n",
       "      <td>3.6630</td>\n",
       "      <td>34.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 14:00:00</td>\n",
       "      <td>3.3105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.926910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>34.953003</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>34.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 15:00:00</td>\n",
       "      <td>3.1996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.920109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>34.953003</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>34.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 16:00:00</td>\n",
       "      <td>3.3045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.922409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6685</td>\n",
       "      <td>34.953003</td>\n",
       "      <td>3.6685</td>\n",
       "      <td>34.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 17:00:00</td>\n",
       "      <td>3.3850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.919609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6570</td>\n",
       "      <td>34.952499</td>\n",
       "      <td>3.6570</td>\n",
       "      <td>34.952499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 18:00:00</td>\n",
       "      <td>3.3211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.924210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6510</td>\n",
       "      <td>34.952003</td>\n",
       "      <td>3.6510</td>\n",
       "      <td>34.952003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 19:00:00</td>\n",
       "      <td>3.3075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.923012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6500</td>\n",
       "      <td>34.952003</td>\n",
       "      <td>3.6500</td>\n",
       "      <td>34.952003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 20:00:00</td>\n",
       "      <td>3.2128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.917912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6470</td>\n",
       "      <td>34.952003</td>\n",
       "      <td>3.6470</td>\n",
       "      <td>34.952003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>2020-08-25 21:00:00</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.928108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.203</td>\n",
       "      <td>65.829002</td>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>3.6320</td>\n",
       "      <td>34.952003</td>\n",
       "      <td>3.6320</td>\n",
       "      <td>34.952003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEPTH                TIME    TEMP  TEMP_QC       PSAL  PSAL_QC    LON  \\\n",
       "0  500.0 2020-08-25 12:00:00  3.4393      1.0  34.927509      1.0  2.203   \n",
       "1  500.0 2020-08-25 13:00:00  3.2461      1.0  34.923210      1.0  2.203   \n",
       "2  500.0 2020-08-25 14:00:00  3.3105      1.0  34.926910      1.0  2.203   \n",
       "3  500.0 2020-08-25 15:00:00  3.1996      1.0  34.920109      1.0  2.203   \n",
       "4  500.0 2020-08-25 16:00:00  3.3045      1.0  34.922409      1.0  2.203   \n",
       "5  500.0 2020-08-25 17:00:00  3.3850      1.0  34.919609      1.0  2.203   \n",
       "6  500.0 2020-08-25 18:00:00  3.3211      1.0  34.924210      1.0  2.203   \n",
       "7  500.0 2020-08-25 19:00:00  3.3075      1.0  34.923012      1.0  2.203   \n",
       "8  500.0 2020-08-25 20:00:00  3.2128      1.0  34.917912      1.0  2.203   \n",
       "9  500.0 2020-08-25 21:00:00  3.4751      1.0  34.928108      1.0  2.203   \n",
       "\n",
       "         LAT    X    Y         DAY    temp       salt  TEMP_MOD   SALT_MOD  \n",
       "0  65.829002  400  333  2020-08-25  3.6405  34.952003    3.6405  34.952003  \n",
       "1  65.829002  400  333  2020-08-25  3.6630  34.953003    3.6630  34.953003  \n",
       "2  65.829002  400  333  2020-08-25  3.6800  34.953003    3.6800  34.953003  \n",
       "3  65.829002  400  333  2020-08-25  3.6800  34.953003    3.6800  34.953003  \n",
       "4  65.829002  400  333  2020-08-25  3.6685  34.953003    3.6685  34.953003  \n",
       "5  65.829002  400  333  2020-08-25  3.6570  34.952499    3.6570  34.952499  \n",
       "6  65.829002  400  333  2020-08-25  3.6510  34.952003    3.6510  34.952003  \n",
       "7  65.829002  400  333  2020-08-25  3.6500  34.952003    3.6500  34.952003  \n",
       "8  65.829002  400  333  2020-08-25  3.6470  34.952003    3.6470  34.952003  \n",
       "9  65.829002  400  333  2020-08-25  3.6320  34.952003    3.6320  34.952003  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aecf536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_QC</th>\n",
       "      <th>PSAL</th>\n",
       "      <th>PSAL_QC</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DAY</th>\n",
       "      <th>temp</th>\n",
       "      <th>salt</th>\n",
       "      <th>TEMP_MOD</th>\n",
       "      <th>SALT_MOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4358</td>\n",
       "      <td>1</td>\n",
       "      <td>34.911854</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 12:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>34.9175</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>34.9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4623</td>\n",
       "      <td>1</td>\n",
       "      <td>34.912240</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 13:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>34.9175</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>34.9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.4573</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910988</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 14:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4505</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910341</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 15:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4569</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910742</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 16:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.4477</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910972</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 17:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.4445</td>\n",
       "      <td>1</td>\n",
       "      <td>34.912828</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 18:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.4573</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910747</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 19:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.4678</td>\n",
       "      <td>1</td>\n",
       "      <td>34.910478</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 20:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.4424</td>\n",
       "      <td>1</td>\n",
       "      <td>34.909580</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 21:00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>66.015</td>\n",
       "      <td>1.983</td>\n",
       "      <td>406</td>\n",
       "      <td>340</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>0.775499</td>\n",
       "      <td>34.9170</td>\n",
       "      <td>0.775499</td>\n",
       "      <td>34.9170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TEMP  TEMP_QC       PSAL  PSAL_QC                TIME  DEPTH     LAT  \\\n",
       "0 -0.4358        1  34.911854        1 2021-11-27 12:00:00   1000  66.015   \n",
       "1 -0.4623        1  34.912240        1 2021-11-27 13:00:00   1000  66.015   \n",
       "2 -0.4573        1  34.910988        1 2021-11-27 14:00:00   1000  66.015   \n",
       "3 -0.4505        1  34.910341        1 2021-11-27 15:00:00   1000  66.015   \n",
       "4 -0.4569        1  34.910742        1 2021-11-27 16:00:00   1000  66.015   \n",
       "5 -0.4477        1  34.910972        1 2021-11-27 17:00:00   1000  66.015   \n",
       "6 -0.4445        1  34.912828        1 2021-11-27 18:00:00   1000  66.015   \n",
       "7 -0.4573        1  34.910747        1 2021-11-27 19:00:00   1000  66.015   \n",
       "8 -0.4678        1  34.910478        1 2021-11-27 20:00:00   1000  66.015   \n",
       "9 -0.4424        1  34.909580        1 2021-11-27 21:00:00   1000  66.015   \n",
       "\n",
       "     LON    X    Y         DAY      temp     salt  TEMP_MOD  SALT_MOD  \n",
       "0  1.983  406  340  2021-11-27  0.800000  34.9175  0.800000   34.9175  \n",
       "1  1.983  406  340  2021-11-27  0.795500  34.9175  0.795500   34.9175  \n",
       "2  1.983  406  340  2021-11-27  0.790500  34.9170  0.790500   34.9170  \n",
       "3  1.983  406  340  2021-11-27  0.788000  34.9170  0.788000   34.9170  \n",
       "4  1.983  406  340  2021-11-27  0.788000  34.9170  0.788000   34.9170  \n",
       "5  1.983  406  340  2021-11-27  0.788000  34.9170  0.788000   34.9170  \n",
       "6  1.983  406  340  2021-11-27  0.787000  34.9170  0.787000   34.9170  \n",
       "7  1.983  406  340  2021-11-27  0.784500  34.9170  0.784500   34.9170  \n",
       "8  1.983  406  340  2021-11-27  0.779500  34.9170  0.779500   34.9170  \n",
       "9  1.983  406  340  2021-11-27  0.775499  34.9170  0.775499   34.9170  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbe06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
